Metadata-Version: 2.4
Name: etl-pdf-pipeline
Version: 0.1.0
Summary: ETL Pipeline for PDF Document Processing with vector embeddings
Author: Houmy Team
License: MIT
Project-URL: Homepage, https://github.com/houmy/etl-pdf-pipeline
Project-URL: Repository, https://github.com/houmy/etl-pdf-pipeline
Keywords: etl,pdf,embeddings,rag,vector-search,langchain
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Text Processing :: Indexing
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: pymupdf>=1.23.0
Requires-Dist: pymupdf4llm>=0.0.5
Requires-Dist: langchain>=0.1.0
Requires-Dist: langchain-text-splitters>=0.0.1
Requires-Dist: tiktoken>=0.5.0
Requires-Dist: sentence-transformers>=2.2.0
Requires-Dist: openai>=1.0.0
Requires-Dist: lancedb>=0.4.0
Requires-Dist: pyarrow>=14.0.0
Requires-Dist: Pillow>=10.0.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: tqdm>=4.66.0
Requires-Dist: pydantic>=2.0.0
Requires-Dist: pyyaml>=6.0
Provides-Extra: api
Requires-Dist: fastapi>=0.104.0; extra == "api"
Requires-Dist: uvicorn[standard]>=0.24.0; extra == "api"
Requires-Dist: python-multipart>=0.0.6; extra == "api"
Provides-Extra: supabase
Requires-Dist: psycopg2-binary>=2.9.9; extra == "supabase"
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Provides-Extra: all
Requires-Dist: etl-pdf-pipeline[api,dev,supabase]; extra == "all"

# ETL PDF Pipeline

A comprehensive ETL pipeline for extracting, transforming, and loading PDF documents into vector databases for RAG (Retrieval-Augmented Generation) applications.

## Installation

```bash
# Install from GitHub
pip install git+https://github.com/dabsdamoon/ETL-pdf-pipepline.git@main

# Or install locally for development
pip install -e /path/to/ETL-pdf-pipeline
```

## Quick Start

```python
from etl_pdf_pipeline import extract_pdf, chunk_text, embed_chunks

# Extract PDF to markdown
markdown, metadata = extract_pdf("document.pdf")

# Chunk the text
chunks = chunk_text(markdown, document_id=metadata["document_id"], title=metadata["title"])

# Generate embeddings
embedded_chunks = embed_chunks(chunks)
```

## Extraction Methods

### PyMuPDF (Default)

Uses PyMuPDF/pymupdf4llm for fast text extraction. Best for digital PDFs with selectable text.

```python
from etl_pdf_pipeline import extract_pdf

markdown, metadata = extract_pdf("document.pdf")
```

### Google Vision OCR

Uses Google Cloud Vision API for OCR extraction. Best for scanned PDFs or documents with complex layouts.

#### Setup

1. **Create a Google Cloud Project** and enable the Vision API:
   - Go to [Google Cloud Console](https://console.cloud.google.com/)
   - Create a new project or select an existing one
   - Enable the [Cloud Vision API](https://console.cloud.google.com/apis/library/vision.googleapis.com)

2. **Set up authentication** (choose one method):

   **Option A: Service Account (Recommended for production)**
   ```bash
   # Create a service account and download the JSON key
   # Then set the environment variable:
   export GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account-key.json"
   ```

   **Option B: Application Default Credentials (for local development)**
   ```bash
   # Login with gcloud CLI
   gcloud auth application-default login
   ```

3. **Install the required package:**
   ```bash
   pip install google-cloud-vision
   ```

#### Usage

```python
from etl_pdf_pipeline import extract_pdf, Config, ExtractionConfig

# Configure Google Vision OCR extraction
config = Config(
    extraction=ExtractionConfig(method="google_vision")
)

# Extract with OCR
markdown, metadata = extract_pdf("scanned_document.pdf", config=config)
print(metadata["extraction_method"])  # "google_vision"
```

## Configuration

### Full Configuration Example

```python
from etl_pdf_pipeline import Config, ExtractionConfig, ChunkingConfig, EmbeddingConfig

config = Config(
    extraction=ExtractionConfig(
        method="pymupdf",      # "pymupdf" or "google_vision"
        ocr_dpi=300,           # DPI for OCR page rendering
    ),
    chunking=ChunkingConfig(
        chunk_size=512,        # Tokens per chunk
        chunk_overlap=50,      # Overlap between chunks
    ),
    embedding=EmbeddingConfig(
        provider="openai",     # "openai" or "local"
        openai_model="text-embedding-3-small",
        local_model="all-MiniLM-L6-v2",
    ),
)
```

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `OPENAI_API_KEY` | OpenAI API key for embeddings | Yes (if using OpenAI embeddings) |
| `GOOGLE_APPLICATION_CREDENTIALS` | Path to Google Cloud service account JSON | Yes (if using Google Vision OCR) |
| `ENVIRONMENT` | Set to "production" to default to OpenAI embeddings | No |

## API Reference

### `extract_pdf(pdf_path, document_id=None, config=None)`

Extract text from a PDF file to markdown.

**Parameters:**
- `pdf_path` (str): Path to the PDF file
- `document_id` (str, optional): Unique document identifier
- `config` (Config, optional): Configuration object

**Returns:**
- `tuple[str, dict]`: (markdown_content, metadata)

### `chunk_text(text, document_id=None, title="", config=None)`

Chunk text content using hybrid markdown-aware chunking.

**Parameters:**
- `text` (str): Text or markdown content to chunk
- `document_id` (str, optional): Document identifier
- `title` (str, optional): Document title
- `config` (Config, optional): Configuration object

**Returns:**
- `list[Chunk]`: List of Chunk objects

### `embed_chunks(chunks, config=None)`

Generate embeddings for chunks.

**Parameters:**
- `chunks` (list[Chunk]): List of Chunk objects
- `config` (Config, optional): Configuration object

**Returns:**
- `list[Chunk]`: Chunks with embeddings populated

### `process_pdf(pdf_path, config=None)`

Full ETL pipeline: extract, chunk, and embed a PDF.

**Parameters:**
- `pdf_path` (str): Path to the PDF file
- `config` (Config, optional): Configuration object

**Returns:**
- `tuple[list[Chunk], dict]`: (embedded_chunks, metadata)

## License

MIT
